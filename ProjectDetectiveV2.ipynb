{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a288f2f1",
   "metadata": {},
   "source": [
    "## Caricamento e operazioni sul dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0507dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metodi disponibili:\n",
      "method\n",
      "stylegan2                  1000000\n",
      "lsun                        539163\n",
      "coco                        163846\n",
      "taming_transformer          105000\n",
      "stylegan3                    97494\n",
      "imagenet                     96788\n",
      "ffhq                         70000\n",
      "mat                          60000\n",
      "pro_gan                      40000\n",
      "afhq                         31933\n",
      "celebahq                     30000\n",
      "lama                         24705\n",
      "generative_inpainting        22000\n",
      "stable_diffusion             21444\n",
      "glide                        20903\n",
      "latent_diffusion             20000\n",
      "diffusion_gan                15507\n",
      "cycle_gan                    15210\n",
      "projected_gan                12000\n",
      "cips                         11200\n",
      "vq_diffusion                 10000\n",
      "gansformer                   10000\n",
      "sfhq                         10000\n",
      "big_gan                      10000\n",
      "denoising_diffusion_gan      10000\n",
      "stylegan1                    10000\n",
      "face_synthetics              10000\n",
      "star_gan                      9995\n",
      "gau_gan                       7000\n",
      "palette                       6000\n",
      "landscape                     4318\n",
      "metfaces                      1336\n",
      "ddpm                           896\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "FILTRO VARIANZA ZERO\n",
      "============================================================\n",
      "Inizio filtro varianza zero su 20000 immagini...\n",
      "Soglia varianza: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolando varianze: 100%|██████████| 20/20 [10:14<00:00, 30.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistiche Filtro Varianza: Latent Diffusion ---\n",
      "Immagini totali:      20000\n",
      "Immagini valide:      20000\n",
      "Immagini rimosse:         0\n",
      "Percentuale rimossa:   0.00%\n",
      "Varianza min:          3.46e+00\n",
      "Varianza max:          1.45e+04\n",
      "Varianza media:        3.45e+03\n",
      "Varianza mediana:      3.18e+03\n",
      "Inizio filtro varianza zero su 21444 immagini...\n",
      "Soglia varianza: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolando varianze: 100%|██████████| 22/22 [06:47<00:00, 18.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistiche Filtro Varianza: Stable Diffusion ---\n",
      "Immagini totali:      21444\n",
      "Immagini valide:      21334\n",
      "Immagini rimosse:       110\n",
      "Percentuale rimossa:   0.51%\n",
      "Varianza min:          0.00e+00\n",
      "Varianza max:          1.19e+04\n",
      "Varianza media:        4.22e+03\n",
      "Varianza mediana:      4.12e+03\n",
      "Inizio filtro varianza zero su 10000 immagini...\n",
      "Soglia varianza: 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolando varianze: 100%|██████████| 10/10 [03:02<00:00, 18.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistiche Filtro Varianza: COCO Sample ---\n",
      "Immagini totali:      10000\n",
      "Immagini valide:      10000\n",
      "Immagini rimosse:         0\n",
      "Percentuale rimossa:   0.00%\n",
      "Varianza min:          3.81e+01\n",
      "Varianza max:          1.37e+04\n",
      "Varianza media:        3.46e+03\n",
      "Varianza mediana:      3.28e+03\n",
      "\n",
      "============================================================\n",
      "REPORT FINALE\n",
      "============================================================\n",
      "Selezionate dopo filtro varianza:\n",
      "  - Latent Diffusion:   20000 /  20000 originali\n",
      "  - Stable Diffusion:   21334 /  21444 originali\n",
      "  - COCO (train2017):   10000 /  10000 originali\n",
      "  - TOTALE:             51334\n",
      "\n",
      "Immagini rimosse per varianza zero: 110 (0.21%)\n",
      "\n",
      "Forma del DataFrame finale: (51334, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51334 entries, 0 to 51333\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   filename         51334 non-null  object\n",
      " 1   image_path       51334 non-null  object\n",
      " 2   target           51334 non-null  int64 \n",
      " 3   category         32444 non-null  object\n",
      " 4   metadata_dir     51334 non-null  object\n",
      " 5   label            51334 non-null  int64 \n",
      " 6   image_path_full  51334 non-null  object\n",
      " 7   method           51334 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "             target         label\n",
      "count  51334.000000  51334.000000\n",
      "mean       4.831184      0.805197\n",
      "std        2.376315      0.396053\n",
      "min        0.000000      0.000000\n",
      "25%        6.000000      1.000000\n",
      "50%        6.000000      1.000000\n",
      "75%        6.000000      1.000000\n",
      "max        6.000000      1.000000\n",
      "        filename                    image_path  target    category  \\\n",
      "0  img009890.jpg   latentdiff/99/img009890.jpg       6  latentdiff   \n",
      "1  img001375.jpg  latentdiff/221/img001375.jpg       6  latentdiff   \n",
      "2  img004738.jpg  latentdiff/524/img004738.jpg       6  latentdiff   \n",
      "3  img006914.jpg  latentdiff/720/img006914.jpg       6  latentdiff   \n",
      "4  img009359.jpg  latentdiff/940/img009359.jpg       6  latentdiff   \n",
      "\n",
      "                                        metadata_dir  label  \\\n",
      "0  /home/alessandro/.cache/kagglehub/datasets/aws...      1   \n",
      "1  /home/alessandro/.cache/kagglehub/datasets/aws...      1   \n",
      "2  /home/alessandro/.cache/kagglehub/datasets/aws...      1   \n",
      "3  /home/alessandro/.cache/kagglehub/datasets/aws...      1   \n",
      "4  /home/alessandro/.cache/kagglehub/datasets/aws...      1   \n",
      "\n",
      "                                     image_path_full            method  \n",
      "0  /home/alessandro/.cache/kagglehub/datasets/aws...  latent_diffusion  \n",
      "1  /home/alessandro/.cache/kagglehub/datasets/aws...  latent_diffusion  \n",
      "2  /home/alessandro/.cache/kagglehub/datasets/aws...  latent_diffusion  \n",
      "3  /home/alessandro/.cache/kagglehub/datasets/aws...  latent_diffusion  \n",
      "4  /home/alessandro/.cache/kagglehub/datasets/aws...  latent_diffusion  \n",
      "            filename                             image_path  target  \\\n",
      "51329  img065873.jpg  coco/coco2017/train2017/img065873.jpg       0   \n",
      "51330  img041710.jpg  coco/coco2017/train2017/img041710.jpg       0   \n",
      "51331  img147039.jpg  coco/coco2017/train2017/img147039.jpg       0   \n",
      "51332  img116104.jpg  coco/coco2017/train2017/img116104.jpg       0   \n",
      "51333  img146399.jpg  coco/coco2017/train2017/img146399.jpg       0   \n",
      "\n",
      "        category                                       metadata_dir  label  \\\n",
      "51329  train2017  /home/alessandro/.cache/kagglehub/datasets/aws...      0   \n",
      "51330  train2017  /home/alessandro/.cache/kagglehub/datasets/aws...      0   \n",
      "51331  train2017  /home/alessandro/.cache/kagglehub/datasets/aws...      0   \n",
      "51332  train2017  /home/alessandro/.cache/kagglehub/datasets/aws...      0   \n",
      "51333  train2017  /home/alessandro/.cache/kagglehub/datasets/aws...      0   \n",
      "\n",
      "                                         image_path_full method  \n",
      "51329  /home/alessandro/.cache/kagglehub/datasets/aws...   coco  \n",
      "51330  /home/alessandro/.cache/kagglehub/datasets/aws...   coco  \n",
      "51331  /home/alessandro/.cache/kagglehub/datasets/aws...   coco  \n",
      "51332  /home/alessandro/.cache/kagglehub/datasets/aws...   coco  \n",
      "51333  /home/alessandro/.cache/kagglehub/datasets/aws...   coco  \n"
     ]
    }
   ],
   "source": [
    "from utils import data_manipulation\n",
    "\n",
    "df = data_manipulation.load_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f2543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metodi trovati: ['latent_diffusion' 'stable_diffusion' 'coco']\n",
      "\n",
      "Distribuzione immagini per metodo:\n",
      "method\n",
      "stable_diffusion    21334\n",
      "latent_diffusion    20000\n",
      "coco                10000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Processando latent_diffusion (20000 immagini) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linkando latent_diffusion: 100%|██████████| 20000/20000 [00:08<00:00, 2282.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processando stable_diffusion (21334 immagini) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linkando stable_diffusion: 100%|██████████| 21334/21334 [00:08<00:00, 2664.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processando coco (10000 immagini) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linkando coco: 100%|██████████| 10000/10000 [00:03<00:00, 2741.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "REPORT FINALE:\n",
      "==================================================\n",
      "latent_diffusion    :  20000 /  20000 linkate\n",
      "stable_diffusion    :  21334 /  21334 linkate\n",
      "coco                :  10000 /  10000 linkate\n",
      "==================================================\n",
      "TOTALE LINKATE:       51334 /  51334\n",
      "\n",
      "Cartelle create in: /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets\n",
      "  - latent_diffusion/: 20000 link simbolici\n",
      "  - stable_diffusion/: 21334 link simbolici\n",
      "  - coco/: 10000 link simbolici\n",
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/latent_diffusion\n",
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/stable_diffusion\n",
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/coco\n"
     ]
    }
   ],
   "source": [
    "sub_folders_paths = data_manipulation.organize_images_with_symlinks(df)\n",
    "\n",
    "for folder in sub_folders_paths:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c703f255",
   "metadata": {},
   "source": [
    "## Definizione delle trasformazioni e del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93bc913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "base_transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "class ArtifactDataset(Dataset):\n",
    "    def __init__(self, df, transform=base_transform):\n",
    "        self.samples = list(zip(\n",
    "            df['image_path_full'].tolist(),\n",
    "            df['label'].tolist()\n",
    "        ))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        return self.transform(img), label\n",
    "    \n",
    "# Split stratificato e DataLoader\n",
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=seed\n",
    ")\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test  = df_test.reset_index(drop=True)\n",
    "\n",
    "# Helper per creare DataLoader\n",
    "def make_loader(df, batch_size=64, shuffle=False, workers=8):\n",
    "    ds = ArtifactDataset(df)\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(df_train, shuffle=True)\n",
    "test_loader  = make_loader(df_test,  shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988da013",
   "metadata": {},
   "source": [
    "## Preparazione backbone ViT in FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770d55c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configurazione modello ViT e Backbone\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "vit = vit_b_16(weights=weights).to(device).eval()\n",
    "if device.type == 'cuda':\n",
    "    vit.half()\n",
    "\n",
    "class ViTBackbone(nn.Module):\n",
    "    def __init__(self, vit_model):\n",
    "        super().__init__()\n",
    "        self._process_input = vit_model._process_input\n",
    "        self.class_token    = vit_model.class_token\n",
    "        self.encoder        = vit_model.encoder\n",
    "        self.norm           = (\n",
    "            vit_model.encoder.ln if hasattr(vit_model.encoder, 'ln')\n",
    "            else vit_model.encoder.norm\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._process_input(x)\n",
    "        B = x.size(0)\n",
    "        cls = self.class_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.norm(x)\n",
    "        return x[:,0]\n",
    "\n",
    "backbone = ViTBackbone(vit).to(device).eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b594e9d",
   "metadata": {},
   "source": [
    "## Estrazione e salvataggio degli embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2781ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6611d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting:   0%|          | 0/642 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings: (41067, 768)\n",
      "Test embeddings: (10267, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Funzione di estrazione embedding e caching\n",
    "@torch.inference_mode()\n",
    "def extract_embeddings(backbone, loader, device, cache_path=None):\n",
    "    if cache_path and os.path.exists(cache_path):\n",
    "        return joblib.load(cache_path)\n",
    "    backbone.eval()\n",
    "    embs, labs = [], []\n",
    "    for imgs, labels in tqdm(loader, desc=\"Extracting\", leave=False):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        if device.type == 'cuda':\n",
    "            imgs = imgs.half()\n",
    "        feats = backbone(imgs).cpu()\n",
    "        embs.append(feats)\n",
    "        labs.extend(labels)\n",
    "    X = torch.vstack(embs).numpy()\n",
    "    y = np.array(labs)\n",
    "    if cache_path:\n",
    "        joblib.dump((X, y), cache_path)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Estrazione e salvataggio degli embeddings\n",
    "\n",
    "# definisci il folder per gli embeddings\n",
    "project_root   = Path.cwd()\n",
    "emb_cache_dir  = project_root / \"cache\" / \"embeddings\"\n",
    "emb_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# file di cache\n",
    "train_cache = emb_cache_dir / \"train_embeddings.joblib\"\n",
    "test_cache  = emb_cache_dir / \"test_embeddings.joblib\"\n",
    "\n",
    "\n",
    "X_train, y_train = extract_embeddings(\n",
    "    backbone,\n",
    "    train_loader,\n",
    "    device,\n",
    "    str(train_cache)\n",
    ")\n",
    "X_test, y_test = extract_embeddings(\n",
    "    backbone,\n",
    "    test_loader,\n",
    "    device,\n",
    "    str(test_cache)\n",
    ")\n",
    "\n",
    "print(\"Train embeddings:\", X_train.shape)\n",
    "print(\"Test embeddings:\",  X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41cfe58",
   "metadata": {},
   "source": [
    "## Allenamento e valutazione dei classificatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5913f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train: (41067, 768)\n",
      "Shape y_train: (41067,)\n",
      "Shape X_test:  (10267, 768)\n",
      "Shape y_test:  (10267,)\n"
     ]
    }
   ],
   "source": [
    "# Caricamento degli embedding da disco\n",
    "\n",
    "# Import librerie per classificatori e metriche\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "project_root      = Path.cwd()\n",
    "emb_cache_dir     = project_root / \"cache\" / \"embeddings\"\n",
    "train_cache_path  = emb_cache_dir / \"train_embeddings.joblib\"\n",
    "test_cache_path   = emb_cache_dir / \"test_embeddings.joblib\"\n",
    "\n",
    "if not train_cache_path.exists():\n",
    "    raise FileNotFoundError(f\"Non trovo {train_cache_path}\")\n",
    "if not test_cache_path.exists():\n",
    "    raise FileNotFoundError(f\"Non trovo {test_cache_path}\")\n",
    "\n",
    "X_train, y_train = joblib.load(train_cache_path)\n",
    "X_test,  y_test  = joblib.load(test_cache_path)\n",
    "\n",
    "print(\"Shape X_train:\", X_train.shape)\n",
    "print(\"Shape y_train:\", y_train.shape)\n",
    "print(\"Shape X_test: \", X_test.shape)\n",
    "print(\"Shape y_test: \", y_test.shape)\n",
    "\n",
    "\n",
    "def train_and_evaluate(clf, X_train, y_train, X_test, y_test, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Addestra clf su X_train, y_train, valuta su X_test, y_test.\n",
    "    Stampa accuracy, classification report, AUC (se binario).\n",
    "    Salva il modello su disco con nome '{model_name}.joblib'.\n",
    "    \"\"\"\n",
    "    # 1. Addestramento\n",
    "    print(f\"\\n---> Addestramento di {model_name} ...\")\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 2. Predizioni\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 3. Metriche base\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy su test: {acc:.4f}\")\n",
    "\n",
    "    # 4. Report di classificazione\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # 5. Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 6. Se problema binario, calcola anche AUC (usando decision_function o predict_proba)\n",
    "    #    Verifica che y_train abbia esattamente 2 classi uniche\n",
    "    if len(set(y_train)) == 2:\n",
    "        try:\n",
    "            if hasattr(clf, \"predict_proba\"):\n",
    "                y_scores = clf.predict_proba(X_test)[:, 1]\n",
    "            else:\n",
    "                # es. LogisticRegression ha decision_function\n",
    "                y_scores = clf.decision_function(X_test)\n",
    "            auc = roc_auc_score(y_test, y_scores)\n",
    "            print(f\"AUC-ROC su test: {auc:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Impossibile calcolare l'AUC: {e}\")\n",
    "\n",
    "    # 7. Salvataggio modello\n",
    "    project_root   = Path.cwd()\n",
    "    models_dir  = project_root / \"cache\" / \"models\"\n",
    "    models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_path = models_dir / f\"{model_name}.joblib\"\n",
    "    joblib.dump(clf, model_path)\n",
    "    print(f\"Modello salvato in: {model_path}\")\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de93b77",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be13d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Addestramento di logistic_regression ...\n",
      "Accuracy su test: 0.8922\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69      2000\n",
      "           1       0.91      0.96      0.93      8267\n",
      "\n",
      "    accuracy                           0.89     10267\n",
      "   macro avg       0.85      0.79      0.81     10267\n",
      "weighted avg       0.89      0.89      0.89     10267\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1250  750]\n",
      " [ 357 7910]]\n",
      "AUC-ROC su test: 0.9192\n",
      "Modello salvato in: /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/models/logistic_regression.joblib\n"
     ]
    }
   ],
   "source": [
    "# È possibile regolare i parametri a piacere; qui usiamo solver e regularizzazione di base\n",
    "lr_clf = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,\n",
    "    solver='lbfgs',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "trained_lr = train_and_evaluate(\n",
    "    clf=lr_clf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name=\"logistic_regression\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635d7da",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e559f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Addestramento di lightgbm_classifier ...\n",
      "[LightGBM] [Info] Number of positive: 33067, number of negative: 8000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.918791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195456\n",
      "[LightGBM] [Info] Number of data points in the train set: 41067, number of used features: 768\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.805196 -> initscore=1.419094\n",
      "[LightGBM] [Info] Start training from score 1.419094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy su test: 0.8592\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.36      0.50      2000\n",
      "           1       0.86      0.98      0.92      8267\n",
      "\n",
      "    accuracy                           0.86     10267\n",
      "   macro avg       0.84      0.67      0.71     10267\n",
      "weighted avg       0.85      0.86      0.84     10267\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 713 1287]\n",
      " [ 159 8108]]\n",
      "AUC-ROC su test: 0.8911\n",
      "Modello salvato in: /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/models/lightgbm_classifier.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',        # classificazione binaria\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "trained_lgb = train_and_evaluate(\n",
    "    clf=lgb_clf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name=\"lightgbm_classifier\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca601843",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd2d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---> Addestramento di mlp_classifier ...\n",
      "Iteration 1, loss = 0.27919013\n",
      "Iteration 2, loss = 0.16831079\n",
      "Iteration 3, loss = 0.10793421\n",
      "Iteration 4, loss = 0.06894816\n",
      "Iteration 5, loss = 0.04946948\n",
      "Iteration 6, loss = 0.03613069\n",
      "Iteration 7, loss = 0.03366466\n",
      "Iteration 8, loss = 0.03041962\n",
      "Iteration 9, loss = 0.02737288\n",
      "Iteration 10, loss = 0.02444518\n",
      "Iteration 11, loss = 0.02376785\n",
      "Iteration 12, loss = 0.02311260\n",
      "Iteration 13, loss = 0.01714639\n",
      "Iteration 14, loss = 0.02013545\n",
      "Iteration 15, loss = 0.02019859\n",
      "Iteration 16, loss = 0.01542918\n",
      "Iteration 17, loss = 0.02294822\n",
      "Iteration 18, loss = 0.01769559\n",
      "Iteration 19, loss = 0.01796268\n",
      "Iteration 20, loss = 0.01428690\n",
      "Iteration 21, loss = 0.01505338\n",
      "Iteration 22, loss = 0.01754476\n",
      "Iteration 23, loss = 0.01707358\n",
      "Iteration 24, loss = 0.01598318\n",
      "Iteration 25, loss = 0.01673614\n",
      "Iteration 26, loss = 0.01523434\n",
      "Iteration 27, loss = 0.01618171\n",
      "Iteration 28, loss = 0.01211900\n",
      "Iteration 29, loss = 0.01767356\n",
      "Iteration 30, loss = 0.01304683\n",
      "Iteration 31, loss = 0.01768556\n",
      "Iteration 32, loss = 0.01463994\n",
      "Iteration 33, loss = 0.01245968\n",
      "Iteration 34, loss = 0.01518967\n",
      "Iteration 35, loss = 0.01687816\n",
      "Iteration 36, loss = 0.01561906\n",
      "Iteration 37, loss = 0.01294488\n",
      "Iteration 38, loss = 0.01261088\n",
      "Iteration 39, loss = 0.01087560\n",
      "Iteration 40, loss = 0.01718894\n",
      "Iteration 41, loss = 0.01567443\n",
      "Iteration 42, loss = 0.01279139\n",
      "Iteration 43, loss = 0.01523922\n",
      "Iteration 44, loss = 0.01688055\n",
      "Iteration 45, loss = 0.01365669\n",
      "Iteration 46, loss = 0.01530251\n",
      "Iteration 47, loss = 0.01382780\n",
      "Iteration 48, loss = 0.01750468\n",
      "Iteration 49, loss = 0.01120654\n",
      "Iteration 50, loss = 0.01158009\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy su test: 0.9217\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      2000\n",
      "           1       0.94      0.96      0.95      8267\n",
      "\n",
      "    accuracy                           0.92     10267\n",
      "   macro avg       0.89      0.86      0.87     10267\n",
      "weighted avg       0.92      0.92      0.92     10267\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1506  494]\n",
      " [ 310 7957]]\n",
      "AUC-ROC su test: 0.9561\n",
      "Modello salvato in: /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/models/mlp_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256),  # esempio di due hidden layer\n",
    "    activation='relu',              # funzione di attivazione\n",
    "    solver='adam',                  # ottimizzatore\n",
    "    alpha=1e-4,                     # weight decay (L2)\n",
    "    batch_size=64,\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=200,                   # numero di epoche per l'ottimizzazione\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "trained_mlp = train_and_evaluate(\n",
    "    clf=mlp_clf,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    model_name=\"mlp_classifier\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55656ffc",
   "metadata": {},
   "source": [
    "## Angular Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547b27a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eseguo: python SyntheticImagesAnalysis/generate_spectra.py --files_path /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/latent_diffusion --out_dir cache/spectra_output --out_name latent_diffusion\n",
      "Starting generation of spectra\n",
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/latent_diffusion\n",
      "20000\n",
      "Starting to generate fingerprints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:19<00:00, 52.38it/s]\n",
      "100%|██████████| 1000/1000 [00:16<00:00, 60.26it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 119.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eseguo: python SyntheticImagesAnalysis/generate_spectra.py --files_path /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/stable_diffusion --out_dir cache/spectra_output --out_name stable_diffusion\n",
      "Starting generation of spectra\n",
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/stable_diffusion\n",
      "21334\n",
      "Starting to generate fingerprints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 55.39it/s]\n",
      "100%|██████████| 1000/1000 [00:18<00:00, 54.51it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 112.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eseguo: python SyntheticImagesAnalysis/generate_spectra.py --files_path /home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/coco --out_dir cache/spectra_output --out_name coco\n",
      "Starting generation of spectra\n",
      "/home/alessandro/Desktop/BIOMETRIA/PROGETTO/ProjectDetectivev2/cache/data_subsets/coco\n",
      "10000\n",
      "Starting to generate fingerprints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:17<00:00, 57.26it/s]\n",
      "100%|██████████| 1000/1000 [00:16<00:00, 61.32it/s]\n",
      "100%|██████████| 1000/1000 [00:08<00:00, 119.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import List\n",
    "\n",
    "def run_generate_spectra(\n",
    "    files_paths: List[str]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Esegue il comando `python generate_spectra.py` per ogni path nella lista.\n",
    "\n",
    "    Args:\n",
    "        files_paths (List[str]): Lista di percorsi ai file di input.\n",
    "    \"\"\"\n",
    "    # Percorso allo script da eseguire\n",
    "    script_path = \"SyntheticImagesAnalysis/generate_spectra.py\"\n",
    "    # Directory di output comune\n",
    "    out_dir = \"cache/spectra_output\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for path in files_paths:\n",
    "        # Estrae il nome del file senza estensione\n",
    "        file_name = os.path.splitext(os.path.basename(path))[0]\n",
    "        # Directory di output, basata sul nome del file\n",
    "        out_name = file_name\n",
    "\n",
    "        # Costruisce ed esegue il comando\n",
    "        cmd = [\n",
    "            \"python\",\n",
    "            script_path,\n",
    "            \"--files_path\", path,\n",
    "             \"--out_dir\", out_dir,\n",
    "            \"--out_name\", out_name,\n",
    "        ]\n",
    "        print(f\"Eseguo: {' '.join(cmd)}\")\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "run_generate_spectra(sub_folders_paths)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
